version: '3.3'

services:
  vllm:
    container_name: vllm-cont
    image: vllm:v1
    restart: always
    platform: linux/amd64
    # env_file:
    #   - .env 
    build:
      context: .
      dockerfile: ./Dockerfile
      args:
        DOCKER_BUILDKIT: 1  
    volumes:
      - "../../model-store/:/model-store"
    ports:
      - "3006:3006"
    networks:
      - llm-net
    environment:
      HOST: "0.0.0.0"
      PORT: "3006"
      # CMAKE_ARGS: "-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS"
      # FORCE_CMAKE: 1


#   nginx:
#     image: nginx:latest 
#     build: 
#         context: .
#         dockerfile: ./Dockerfile_nginx      
#     ports:
#       - "3002:3002"
#     depends_on:
#       - embed  
#     networks:
#       - llm-net   

networks:
  llm-net:
    name: llm-net
    external: true