SERVER_PORT=3001
CACHE_VECTORS=true
AUTH_TOKEN=Y2AGAC6-4N0MTN0-QH0BD7E-17FNMVN
# JWT_SECRET="my-random-string-for-seeding" # Only needed if AUTH_TOKEN is set. Please generate random string at least 12 chars long.
DISABLE_TELEMETRY=true
###########################################
######## LLM API SElECTION ################
###########################################
LLM_PROVIDER=openai
OPEN_AI_KEY=
OPEN_MODEL_PREF=gpt-3.5-turbo

DEVICE=cpu
MODE=production
MODELS_PATH=model-store

################ COMPLETION model ###############
COMPLETION_MODEL_NAME=/model-store/mistralai/Mistral-7B-Instruct-v0.1
# COMPLETION_MODEL_NAME=/model-store/mistral-7b-instruct-v0.1.Q4_K_M.gguf
# COMPLETION_MODEL_NAME='/model-store/llama-2-7b-chat.Q4_K_M.gguf'


###### COMPLETION models endpoints ###############
# COMPLETION_MODEL_ENDPOINT=http://46.254.21.170:3003
# COMPLETION_MODEL_ENDPOINT=http://llm-server:3003
COMPLETION_MODEL_ENDPOINT=http://llm-server:3003

# GPU:
# COMPLETION_MODEL_ENDPOINT=http://194.135.112.219:3003
# COMPLETION_MODEL_ENDPOINT='http://vllm:3003'


################ Embedding models #########
# EMBEDDING_MODEL_NAME = "hkunlp/instructor-large" #  has'nt been trained on Russian
# EMBEDDING_MODEL_NAME = "intfloat/e5-large-v2" # Uses 1.5 GB of VRAM (A little less accurate than instructor-large)
# EMBEDDING_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"
# EMBEDDING_MODEL_NAME=sentence-transformers/multi-qa-mpnet-base-dot-v1
# EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_MODEL_NAME=sentence-transformers/distiluse-base-multilingual-cased-v1

EMBEDDING_MODEL_NAME=sentence-transformers/all-distilroberta-v1
EMBEDDING_MODEL_ENDPOINT=http://embed:3004
# EMBEDDING_MODEL_ENDPOINT =http://46.254.21.170:3004


EMBED_AUTH_TOKEN=
X_API_TOKEN=1
# X_API_TOKEN=
PORT=3004
HOST=0.0.0.0
# postgresql://username:password@host:port/database  
# host=postgres (service name in docker-compose)

# in a conatiner
DATABASE_URL=postgresql://postgres:example@postgres:5432/postgres
# DATABASE_URL=postgresql://postgres:example@localhost:5432/postgres
AVER_WORD_TOKENS=3

# LLM_PROVIDER='azure'
# AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_KEY=
# OPEN_MODEL_PREF='my-gpt35-deployment' # This is the "deployment" on Azure you want to use. Not the base model.
# EMBEDDING_MODEL_PREF='embedder-model' # This is the "deployment" on Azure you want to use for embeddings. Not the base model. Valid base model is text-embedding-ada-002


###########################################
######## Vector Database Selection ########
###########################################
# Enable all below if you are using vector database: Chroma.
# VECTOR_DB="chroma"
# CHROMA_ENDPOINT='http://host.docker.internal:8000'
# CHROMA_API_HEADER="X-Api-Key"
# CHROMA_API_KEY="sk-123abc"

# Enable all below if you are using vector database: Pinecone.
# VECTOR_DB="pinecone"
# PINECONE_ENVIRONMENT=
# PINECONE_API_KEY=
# PINECONE_INDEX=

# Enable all below if you are using vector database: LanceDB.
VECTOR_DB=lancedb

# Enable all below if you are using vector database: Weaviate.
# VECTOR_DB="weaviate"
# WEAVIATE_ENDPOINT="http://localhost:8080"
# WEAVIATE_API_KEY=

# Enable all below if you are using vector database: Qdrant.
# VECTOR_DB="qdrant"
# QDRANT_ENDPOINT="http://localhost:6333"
# QDRANT_API_KEY=

# CLOUD DEPLOYMENT VARIRABLES ONLY
# AUTH_TOKEN="hunter2" # This is the password to your application if remote hosting.
# NO_DEBUG="true"

STORAGE_DIR=./server/storage
GOOGLE_APIS_KEY=
ARG_UID=1000
ARG_GID=1000
