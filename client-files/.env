# DEVICE=gpu
DEVICE=cpu

################ COMPLETION model ###############
COMPLETION_MODEL_NAME=/model-store/mistralai/Mistral-7B-Instruct-v0.1
# COMPLETION_MODEL_NAME=/model-store/mistral-7b-instruct-v0.1.Q4_K_M.gguf

# /localRAG/llama-cpp-python/docker/simple/run.sh - defines the model name foe llama.cpp
# COMPLETION_MODEL_NAME=/model-store/llama-2-7b-chat.Q4_K_M.gguf
################ Embedding models #########
EMBEDDING_MODEL_NAME=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_MODEL_NAME=sentence-transformers/all-mpnet-base-v2
# EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_MODEL_NAME=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

###### COMPLETION models endpoints ###############
# CPU:
COMPLETION_MODEL_ENDPOINT=http://46.254.21.170:3003
# COMPLETION_MODEL_ENDPOINT=http://llm-server:3003

# GPU:
# COMPLETION_MODEL_ENDPOINT=http://194.135.112.219:3003
# COMPLETION_MODEL_ENDPOINT=http://vllm:3003

EMBEDDING_MODEL_ENDPOINT=http://embed:3004
# EMBEDDING_MODEL_ENDPOINT=http://46.254.21.170:3004



AVER_WORD_TOKENS=3
# HINT: postgresql://username:password@host:port/database  
#       host=postgres (service name in docker-compose)
# postgres running in a CONTAINER as a service
DATABASE_URL=postgresql://postgres:example@postgres:5432/postgres
# postgres as a process running locally on mac
# DATABASE_URL=postgresql://postgres:example@localhost:5432/postgres




SERVER_PORT=3001
CACHE_VECTORS=true
AUTH_TOKEN=Y2AGAC6-4N0MTN0-QH0BD7E-17FNMVN
# JWT_SECRET="my-random-string-for-seeding" # Only needed if AUTH_TOKEN is set. Please generate random string at least 12 chars long.
DISABLE_TELEMETRY=true
LLM_PROVIDER=openai
OPEN_AI_KEY=
OPEN_MODEL_PREF=gpt-3.5-turbo


MODE=production
MODELS_PATH=model-store
VECTOR_DB=lancedb
STORAGE_DIR=./server/storage
GOOGLE_APIS_KEY=
ARG_UID=1000
ARG_GID=1000

EMBED_AUTH_TOKEN=
X_API_TOKEN=1
# X_API_TOKEN=
PORT=3004
HOST=0.0.0.0


###########################################
######## Vector Database Selection ########
###########################################
# Enable all below if you are using vector database: Chroma.
# VECTOR_DB="chroma"
# CHROMA_ENDPOINT='http://host.docker.internal:8000'
# CHROMA_API_HEADER="X-Api-Key"
# CHROMA_API_KEY="sk-123abc"

# Enable all below if you are using vector database: Pinecone.
# VECTOR_DB="pinecone"
# PINECONE_ENVIRONMENT=
# PINECONE_API_KEY=
# PINECONE_INDEX=

# Enable all below if you are using vector database: LanceDB.
# VECTOR_DB=lancedb

# Enable all below if you are using vector database: Weaviate.
# VECTOR_DB="weaviate"
# WEAVIATE_ENDPOINT="http://localhost:8080"
# WEAVIATE_API_KEY=

# Enable all below if you are using vector database: Qdrant.
# VECTOR_DB="qdrant"
# QDRANT_ENDPOINT="http://localhost:6333"
# QDRANT_API_KEY=

# CLOUD DEPLOYMENT VARIRABLES ONLY
# AUTH_TOKEN="hunter2" # This is the password to your application if remote hosting.
# NO_DEBUG="true"